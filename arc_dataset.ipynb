{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenizer and Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tokenizer import ARCTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 18\n",
            "Special tokens: {'PAD': 10, 'SOS': 11, 'EOS': 12, 'TRAIN': 13, 'TEST': 14, 'INPUT': 15, 'OUTPUT': 16, 'NEWLINE': 17}\n",
            "\n",
            "Test grid: [[1, 2, 3], [4, 5, 6]]\n",
            "Tokens: [1, 2, 3, 17, 4, 5, 6]\n",
            "Back to grid: [[1, 2, 3], [4, 5, 6]]\n"
          ]
        }
      ],
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = ARCTokenizer()\n",
        "print(f\"Vocabulary size: {tokenizer.vocab_size}\")\n",
        "print(f\"Special tokens: {tokenizer.token_to_id}\")\n",
        "\n",
        "# Test tokenizer\n",
        "test_grid = [[1, 2, 3], [4, 5, 6]]\n",
        "tokens = tokenizer.grid_to_tokens(test_grid)\n",
        "print(f\"\\nTest grid: {test_grid}\")\n",
        "print(f\"Tokens: {tokens}\")\n",
        "print(f\"Back to grid: {tokenizer.tokens_to_grid(tokens, (2, 3))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Token converter (enrich with position info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from token_converter import TokenTo3DConverter\n",
        "# Initialize converter\n",
        "token_converter = TokenTo3DConverter(tokenizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loader with Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from dataset import ARCDataset, ARCTorchDataset \n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datasets...\n",
            "Training challenges: 400\n",
            "Test challenges: 100\n",
            "\n",
            "Training samples (with augmentation): 400\n",
            "Test samples: 100\n",
            "\n",
            "Sample data:\n",
            "Sample ID: 007bbfb7\n",
            "Challenge ID: 007bbfb7\n",
            "Input sequence length: 5400\n",
            "Target sequence length: 1000\n",
            "Input dims: [(3, 3), (3, 3)]\n",
            "Output dims: [(9, 9), (9, 9)]\n",
            "Test input dims: (3, 3)\n",
            "Test output dims: (9, 9)\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "print(\"Loading datasets...\")\n",
        "train_dataset = ARCDataset(\n",
        "    challenges_path='arc-agi_training_challenges.json',\n",
        "    solutions_path='arc-agi_training_solutions.json'\n",
        ")\n",
        "\n",
        "test_dataset = ARCDataset(\n",
        "    challenges_path='arc-agi_test_challenges.json'\n",
        ")\n",
        "\n",
        "print(f\"Training challenges: {len(train_dataset.get_all_challenges())}\")\n",
        "print(f\"Test challenges: {len(test_dataset.get_all_challenges())}\")\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_torch_dataset = ARCTorchDataset(train_dataset, tokenizer, token_converter=token_converter)\n",
        "test_torch_dataset = ARCTorchDataset(test_dataset, tokenizer, token_converter=token_converter)\n",
        "\n",
        "print(f\"\\nTraining samples (with augmentation): {len(train_torch_dataset)}\")\n",
        "print(f\"Test samples: {len(test_torch_dataset)}\")\n",
        "\n",
        "# Test data loading\n",
        "sample = train_torch_dataset[0]\n",
        "print(f\"\\nSample data:\")\n",
        "print(f\"Sample ID: {sample['sample_id']}\")\n",
        "print(f\"Challenge ID: {sample['challenge_id']}\")\n",
        "print(f\"Input sequence length: {len(sample['input'])}\")\n",
        "print(f\"Target sequence length: {len(sample['target'])}\")\n",
        "print(f\"Input dims: {sample['input_dims']}\")\n",
        "print(f\"Output dims: {sample['output_dims']}\")\n",
        "print(f\"Test input dims: {sample['test_input_dims']}\")\n",
        "print(f\"Test output dims: {sample['test_output_dims']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[11, -1, -1],\n",
              "        [13, -1, -1],\n",
              "        [15, -1, -1],\n",
              "        ...,\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# self.PAD_TOKEN = 10\n",
        "# self.SOS_TOKEN = 11  # Start of sequence\n",
        "# self.EOS_TOKEN = 12  # End of sequence\n",
        "# self.TRAIN_TOKEN = 13  # Start of training example\n",
        "# self.TEST_TOKEN = 14  # Start of test example\n",
        "# self.INPUT_TOKEN = 15  # Start of input grid\n",
        "# self.OUTPUT_TOKEN = 16  # Start of output grid\n",
        "# self.NEWLINE_TOKEN = 17  # Grid separator (], [)\n",
        "train_torch_dataset[0]['input']#[0:300]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[11, -1, -1],\n",
              "        [16, -1, -1],\n",
              "        [ 7,  0,  0],\n",
              "        [ 0,  1,  0],\n",
              "        [ 7,  2,  0],\n",
              "        [ 0,  3,  0],\n",
              "        [ 0,  4,  0],\n",
              "        [ 0,  5,  0],\n",
              "        [ 7,  6,  0],\n",
              "        [ 0,  7,  0],\n",
              "        [ 7,  8,  0],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  1],\n",
              "        [ 0,  1,  1],\n",
              "        [ 7,  2,  1],\n",
              "        [ 0,  3,  1],\n",
              "        [ 0,  4,  1],\n",
              "        [ 0,  5,  1],\n",
              "        [ 7,  6,  1],\n",
              "        [ 0,  7,  1],\n",
              "        [ 7,  8,  1],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  2],\n",
              "        [ 7,  1,  2],\n",
              "        [ 0,  2,  2],\n",
              "        [ 0,  3,  2],\n",
              "        [ 0,  4,  2],\n",
              "        [ 0,  5,  2],\n",
              "        [ 7,  6,  2],\n",
              "        [ 7,  7,  2],\n",
              "        [ 0,  8,  2],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  3],\n",
              "        [ 0,  1,  3],\n",
              "        [ 7,  2,  3],\n",
              "        [ 0,  3,  3],\n",
              "        [ 0,  4,  3],\n",
              "        [ 0,  5,  3],\n",
              "        [ 7,  6,  3],\n",
              "        [ 0,  7,  3],\n",
              "        [ 7,  8,  3],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  4],\n",
              "        [ 0,  1,  4],\n",
              "        [ 7,  2,  4],\n",
              "        [ 0,  3,  4],\n",
              "        [ 0,  4,  4],\n",
              "        [ 0,  5,  4],\n",
              "        [ 7,  6,  4],\n",
              "        [ 0,  7,  4],\n",
              "        [ 7,  8,  4],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  5],\n",
              "        [ 7,  1,  5],\n",
              "        [ 0,  2,  5],\n",
              "        [ 0,  3,  5],\n",
              "        [ 0,  4,  5],\n",
              "        [ 0,  5,  5],\n",
              "        [ 7,  6,  5],\n",
              "        [ 7,  7,  5],\n",
              "        [ 0,  8,  5],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  6],\n",
              "        [ 0,  1,  6],\n",
              "        [ 7,  2,  6],\n",
              "        [ 7,  3,  6],\n",
              "        [ 0,  4,  6],\n",
              "        [ 7,  5,  6],\n",
              "        [ 0,  6,  6],\n",
              "        [ 0,  7,  6],\n",
              "        [ 0,  8,  6],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  7],\n",
              "        [ 0,  1,  7],\n",
              "        [ 7,  2,  7],\n",
              "        [ 7,  3,  7],\n",
              "        [ 0,  4,  7],\n",
              "        [ 7,  5,  7],\n",
              "        [ 0,  6,  7],\n",
              "        [ 0,  7,  7],\n",
              "        [ 0,  8,  7],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  8],\n",
              "        [ 7,  1,  8],\n",
              "        [ 0,  2,  8],\n",
              "        [ 7,  3,  8],\n",
              "        [ 7,  4,  8],\n",
              "        [ 0,  5,  8],\n",
              "        [ 0,  6,  8],\n",
              "        [ 0,  7,  8],\n",
              "        [ 0,  8,  8],\n",
              "        [12, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_torch_dataset[0]['target'][0:300]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400, 100)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_torch_dataset), len(test_torch_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autoregressive Dataset for LLM Training\n",
        "\n",
        "For autoregressive training, we need to:\n",
        "1. Concatenate input + target into one sequence\n",
        "2. Create labels shifted by 1 position (next token prediction)\n",
        "3. Use causal masking so model can't see future tokens\n",
        "\n",
        "**Important**: This is NOT data leakage! During training, the model learns to predict the next token given previous tokens. During inference, we'll use the same autoregressive generation process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from exploded_dataset import ARCExplodedDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating exploded training dataset...\n",
            "Exploding 400 base samples...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400/400 [00:03<00:00, 128.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 60126 exploded samples from 400 base samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create exploded datasets from existing ARCTorchDataset\n",
        "print(\"Creating exploded training dataset...\")\n",
        "train_exploded_dataset = ARCExplodedDataset(train_torch_dataset, tokenizer, sequence_length=5400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    print(train_exploded_dataset[i]['input_3d'][218:228], train_exploded_dataset[i]['target_vector'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## split to val / train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create DataLoader\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function for batching\"\"\"\n",
        "    input_3d = torch.stack([item['input_3d'] for item in batch])\n",
        "    target_values = torch.stack([torch.tensor(item['target_value'], dtype=torch.long) for item in batch])\n",
        "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
        "    \n",
        "    return {\n",
        "        'input_3d': input_3d,\n",
        "        'target_values': target_values,\n",
        "        'attention_mask': attention_mask\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split dataset by challenge_id (ensures no data leakage)\n",
        "# Create TWO validation sets: tiny (frequent) and full (accurate)\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# Group samples by challenge_id\n",
        "challenge_to_indices = defaultdict(list)\n",
        "for idx in range(len(train_exploded_dataset)):\n",
        "    sample = train_exploded_dataset[idx]\n",
        "    challenge_id = sample['challenge_id']\n",
        "    challenge_to_indices[challenge_id].append(idx)\n",
        "\n",
        "# Get unique challenge IDs\n",
        "challenge_ids = list(challenge_to_indices.keys())\n",
        "print(f\"Total challenges: {len(challenge_ids)}\")\n",
        "\n",
        "# Shuffle and split challenges (not individual samples)\n",
        "random.seed(42)\n",
        "random.shuffle(challenge_ids)\n",
        "\n",
        "train_ratio = 0.8\n",
        "split_idx = int(len(challenge_ids) * train_ratio)\n",
        "train_challenge_ids = set(challenge_ids[:split_idx])\n",
        "val_challenge_ids_all = set(challenge_ids[split_idx:])\n",
        "\n",
        "# Split validation challenges into tiny and full\n",
        "val_challenge_ids_list = list(val_challenge_ids_all)\n",
        "random.shuffle(val_challenge_ids_list)\n",
        "tiny_val_ratio = 0.1  # 10% of validation challenges for tiny set\n",
        "tiny_split_idx = int(len(val_challenge_ids_list) * tiny_val_ratio)\n",
        "tiny_val_challenge_ids = set(val_challenge_ids_list[:tiny_split_idx])\n",
        "full_val_challenge_ids = set(val_challenge_ids_list[tiny_split_idx:])\n",
        "\n",
        "print(f\"Train challenges: {len(train_challenge_ids)}\")\n",
        "print(f\"Tiny val challenges: {len(tiny_val_challenge_ids)}\")\n",
        "print(f\"Full val challenges: {len(full_val_challenge_ids)}\")\n",
        "\n",
        "# Collect indices for each split\n",
        "train_indices = []\n",
        "tiny_val_indices = []\n",
        "full_val_indices = []\n",
        "\n",
        "for challenge_id, indices in challenge_to_indices.items():\n",
        "    if challenge_id in train_challenge_ids:\n",
        "        train_indices.extend(indices)\n",
        "    elif challenge_id in tiny_val_challenge_ids:\n",
        "        tiny_val_indices.extend(indices)\n",
        "    elif challenge_id in full_val_challenge_ids:\n",
        "        full_val_indices.extend(indices)\n",
        "\n",
        "print(f\"\\nTrain samples: {len(train_indices)}\")\n",
        "print(f\"Tiny val samples: {len(tiny_val_indices)}\")\n",
        "print(f\"Full val samples: {len(full_val_indices)}\")\n",
        "\n",
        "# Create subset datasets\n",
        "train_dataset_split = Subset(train_exploded_dataset, train_indices)\n",
        "tiny_val_dataset_split = Subset(train_exploded_dataset, tiny_val_indices)\n",
        "full_val_dataset_split = Subset(train_exploded_dataset, full_val_indices)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset_split,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Tiny validation loader (for frequent checks)\n",
        "tiny_val_loader = DataLoader(\n",
        "    tiny_val_dataset_split,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Full validation loader (for accurate metrics)\n",
        "full_val_loader = DataLoader(\n",
        "    full_val_dataset_split,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain batches: {len(train_loader)}\")\n",
        "print(f\"Tiny val batches: {len(tiny_val_loader)}\")\n",
        "print(f\"Full val batches: {len(full_val_loader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modeling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login(key='9c6d131f5fcedb96565fa31f4680c2da83ea07d5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NextTokenPredictor(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer model to predict next token from 3D vectors [value, x, y].\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, vocab_size=18, d_model=16, nhead=8, num_layers=4, \n",
        "                 dim_feedforward=1024, max_seq_length=5400, dropout=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_model = d_model\n",
        "        self.max_seq_length = max_seq_length\n",
        "        \n",
        "        # Embedding for token values (0-17)\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        \n",
        "        # Projection for x, y coordinates (add coordinate information)\n",
        "        self.coord_projection = nn.Linear(2, d_model)  # [x, y] -> d_model\n",
        "        \n",
        "        # Positional encoding (learned)\n",
        "        #self.pos_encoding = nn.Parameter(torch.randn(max_seq_length, d_model) * 0.02)\n",
        "        #self.pos_encoding = self.create_sinusoidal_positional_encoding(max_seq_length, d_model)\n",
        "        pos_encoding = self.create_sinusoidal_positional_encoding(max_seq_length, d_model)\n",
        "        self.register_buffer('pos_encoding', pos_encoding)\n",
        "        \n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        \n",
        "        # Output projection to vocab\n",
        "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def create_sinusoidal_positional_encoding(self, max_len, d_model):\n",
        "        \"\"\"\n",
        "        Create sinusoidal positional encoding (no learnable parameters).\n",
        "        \n",
        "        Args:\n",
        "            max_len: Maximum sequence length\n",
        "            d_model: Model dimension\n",
        "        \n",
        "        Returns:\n",
        "            [max_len, d_model] tensor with positional encodings\n",
        "        \"\"\"\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        \n",
        "        pe[:, 0::2] = torch.sin(position * div_term)  # Even indices: sin\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)  # Odd indices: cos\n",
        "        \n",
        "        return pe  # [max_len, d_model]\n",
        "\n",
        "        \n",
        "    def forward(self, input_3d, attention_mask=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_3d: [batch_size, seq_len, 3] - [value, x, y] vectors\n",
        "            attention_mask: [batch_size, seq_len] - 1 for real tokens, 0 for padding\n",
        "        \n",
        "        Returns:\n",
        "            logits: [batch_size, seq_len, vocab_size] - logits for each position\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = input_3d.shape\n",
        "        \n",
        "        # Extract components\n",
        "        token_values = input_3d[:, :, 0].long()  # [batch_size, seq_len] - token values\n",
        "        coordinates = input_3d[:, :, 1:3].float()  # [batch_size, seq_len, 2] - x, y\n",
        "        \n",
        "        # Embed tokens\n",
        "        token_emb = self.token_embedding(token_values)  # [batch_size, seq_len, d_model]\n",
        "        \n",
        "        # Add coordinate information\n",
        "        coord_emb = self.coord_projection(coordinates)  # [batch_size, seq_len, d_model]\n",
        "        \n",
        "        # Combine token and coordinate embeddings\n",
        "        x = token_emb + coord_emb  # [batch_size, seq_len, d_model]\n",
        "        \n",
        "        # Add positional encoding\n",
        "        x = x + self.pos_encoding[:seq_len].unsqueeze(0)  # [batch_size, seq_len, d_model]\n",
        "        \n",
        "        #x = self.dropout(x)\n",
        "        if attention_mask is not None:\n",
        "            padding_mask = (attention_mask == 0).bool()  # True for padding, False for real tokens\n",
        "        else:\n",
        "            padding_mask = None\n",
        "        \n",
        "        # Apply transformer\n",
        "        x = self.transformer(x, src_key_padding_mask=padding_mask)  # [batch_size, seq_len, d_model]\n",
        "        \n",
        "        # Get logits for all positions\n",
        "        logits = self.output_proj(x)  # [batch_size, seq_len, vocab_size]\n",
        "        \n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model\n",
        "model = NextTokenPredictor(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    d_model=16,\n",
        "    nhead=1,\n",
        "    num_layers=4,\n",
        "    dim_feedforward=128,\n",
        "    max_seq_length=5400,\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "print(f\"Model device: {next(model.parameters()).device}\")\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation function\n",
        "import os\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, batch_idx, val_loss, val_acc, train_loss, train_acc, \n",
        "                   checkpoint_dir='checkpoints', is_best=False):\n",
        "    \"\"\"\n",
        "    Save model checkpoint\n",
        "    \n",
        "    Args:\n",
        "        model: The model to save\n",
        "        optimizer: The optimizer to save\n",
        "        epoch: Current epoch number\n",
        "        batch_idx: Current batch index\n",
        "        val_loss: Validation loss\n",
        "        val_acc: Validation accuracy\n",
        "        train_loss: Training loss\n",
        "        train_acc: Training accuracy\n",
        "        checkpoint_dir: Directory to save checkpoints\n",
        "        is_best: Whether this is the best model so far\n",
        "    \"\"\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    \n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'batch': batch_idx,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'val_loss': val_loss,\n",
        "        'val_accuracy': val_acc,\n",
        "        'train_loss': train_loss,\n",
        "        'train_accuracy': train_acc,\n",
        "    }\n",
        "    \n",
        "    # Save regular checkpoint\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch{epoch}_batch{batch_idx}.pt')\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    \n",
        "    # Save best model if applicable\n",
        "    if is_best:\n",
        "        best_path = os.path.join(checkpoint_dir, 'best_model.pt')\n",
        "        torch.save(checkpoint, best_path)\n",
        "        print(f\"  ✓ Best model saved: {best_path}\")\n",
        "    \n",
        "    return checkpoint_path\n",
        "    \n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    \"\"\"Evaluate model on dataset\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            input_3d = batch['input_3d'].to(device)\n",
        "            target_values = batch['target_values'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            \n",
        "            logits = model(input_3d=input_3d, attention_mask=attention_mask)\n",
        "            \n",
        "            batch_size = input_3d.size(0)\n",
        "            seq_lengths = attention_mask.sum(dim=1) - 1\n",
        "            last_logits = logits[torch.arange(batch_size), seq_lengths]\n",
        "            \n",
        "            loss = criterion(last_logits, target_values)\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "            predictions = last_logits.argmax(dim=1)\n",
        "            correct += (predictions == target_values).sum().item()\n",
        "            total += target_values.size(0)\n",
        "    \n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# Updated train_epoch with periodic validation during training\n",
        "def train_epoch(model, train_dataloader, tiny_val_loader, full_val_loader, criterion, optimizer, device, \n",
        "                log_every_n_batches=2, tiny_val_every_n_batches=10, full_val_every_n_batches=200):\n",
        "    \"\"\"\n",
        "    Train for one epoch with periodic validation using two validation sets\n",
        "    \n",
        "    Args:\n",
        "        model: The model to train\n",
        "        train_dataloader: Training data loader\n",
        "        tiny_val_loader: Tiny validation loader (for frequent checks)\n",
        "        full_val_loader: Full validation loader (for accurate metrics)\n",
        "        criterion: Loss function\n",
        "        optimizer: Optimizer\n",
        "        device: Device to run on\n",
        "        log_every_n_batches: Log to wandb every N batches\n",
        "        tiny_val_every_n_batches: Run tiny validation every N batches (default: 10)\n",
        "        full_val_every_n_batches: Run full validation every N batches (default: 200)\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    best_val_los=1e6\n",
        "    \n",
        "    pbar = tqdm(train_dataloader, desc=\"Training\")\n",
        "    for batch_idx, batch in enumerate(pbar):\n",
        "        # Move to device\n",
        "        input_3d = batch['input_3d'].to(device)  # [batch_size, seq_len, 3]\n",
        "        target_values = batch['target_values'].to(device)  # [batch_size]\n",
        "        attention_mask = batch['attention_mask'].to(device)  # [batch_size, seq_len]\n",
        "        \n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_3d=input_3d, attention_mask=attention_mask)  # [batch_size, seq_len, vocab_size]\n",
        "        \n",
        "        # Get logits for the last non-padding position (where we predict)\n",
        "        # Find last non-padding position for each sequence\n",
        "        batch_size = input_3d.size(0)\n",
        "        seq_lengths = attention_mask.sum(dim=1) - 1  # -1 because we want the position before the target\n",
        "        last_logits = logits[torch.arange(batch_size), seq_lengths]  # [batch_size, vocab_size]\n",
        "        \n",
        "        # Compute loss\n",
        "        loss = criterion(last_logits, target_values)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Metrics\n",
        "        total_loss += loss.item()\n",
        "        predictions = last_logits.argmax(dim=1)\n",
        "        batch_correct = (predictions == target_values).sum().item()\n",
        "        correct += batch_correct\n",
        "        total += target_values.size(0)\n",
        "        batch_acc = 100 * batch_correct / target_values.size(0)\n",
        "        \n",
        "        # Log to wandb every N batches (default: every other batch)\n",
        "        if batch_idx % log_every_n_batches == 0:\n",
        "            wandb.log({\n",
        "                \"batch_loss\": loss.item(),\n",
        "                \"batch_accuracy\": batch_acc,\n",
        "                \"running_accuracy\": 100 * correct / total,\n",
        "            })\n",
        "        \n",
        "        # Tiny validation (frequent, quick check)\n",
        "        if (batch_idx + 1) % tiny_val_every_n_batches == 0:\n",
        "            tiny_val_loss, tiny_val_acc = evaluate(model, tiny_val_loader, criterion, device)\n",
        "            \n",
        "            # Log tiny validation metrics\n",
        "            wandb.log({\n",
        "                \"tiny_val_loss\": tiny_val_avg_loss,\n",
        "                \"tiny_val_accuracy\": tiny_val_acc,\n",
        "                \"train_batch\": batch_idx + 1,\n",
        "            })\n",
        "            \n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'acc': f'{100 * correct / total:.2f}%',\n",
        "                'tiny_val': f'{tiny_val_acc:.1f}%'\n",
        "            })\n",
        "            \n",
        "            model.train()  # Switch back to training mode\n",
        "        \n",
        "        # Full validation (less frequent, more accurate)\n",
        "        if (batch_idx + 1) % full_val_every_n_batches == 0:\n",
        "            full_val_loss, full_val_acc = evaluate(model, full_val_loader, criterion, device)\n",
        "            is_better=full_val_loss<best_val_los\n",
        "            if is_better:\n",
        "                best_val_los=full_val_loss\n",
        "\n",
        "            save_checkpoint(model, optimizer, epoch, batch_idx, val_loss, val_acc, train_loss, train_acc, \n",
        "                   checkpoint_dir='checkpoints', is_best=is_better)\n",
        "            \n",
        "            # Log full validation metrics\n",
        "            wandb.log({\n",
        "                \"full_val_loss\": full_val_avg_loss,\n",
        "                \"full_val_accuracy\": full_val_acc,\n",
        "                \"train_batch\": batch_idx + 1,\n",
        "            })\n",
        "            \n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'acc': f'{100 * correct / total:.2f}%',\n",
        "                'full_val': f'{full_val_acc:.1f}%'\n",
        "            })\n",
        "            \n",
        "            model.train()  # Switch back to training mode\n",
        "        \n",
        "        # Update progress bar (if no validation was run this batch)\n",
        "        if (batch_idx + 1) % tiny_val_every_n_batches != 0 and (batch_idx + 1) % full_val_every_n_batches != 0:\n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'acc': f'{100 * correct / total:.2f}%'\n",
        "            })\n",
        "    \n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Updated training loop with two-tier validation\n",
        "num_epochs = 3\n",
        "print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Validation frequencies\n",
        "tiny_val_every_n_batches = 10   # Tiny validation every 10 batches (~30 seconds)\n",
        "full_val_every_n_batches = 200  # Full validation every 200 batches (~5-10 minutes)\n",
        "\n",
        "num_train_batches = len(train_loader)\n",
        "print(f\"Training batches per epoch: {num_train_batches}\")\n",
        "print(f\"Tiny validation: every {tiny_val_every_n_batches} batches ({max_tiny_val_batches} batches, ~{num_train_batches // tiny_val_every_n_batches} times/epoch)\")\n",
        "print(f\"Full validation: every {full_val_every_n_batches} batches ({max_full_val_batches} batches, ~{num_train_batches // full_val_every_n_batches} times/epoch)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "best_val_acc = 0.0\n",
        "\n",
        "#wandb.init(\n",
        "#    name='test',\n",
        "#    project=\"arc-next-token-prediction\",\n",
        "#    config={\n",
        "#        \"vocab_size\": tokenizer.vocab_size,\n",
        "#        \"d_model\": model.d_model,\n",
        "#        \"nhead\": model.transformer.layers[0].self_attn.num_heads,\n",
        "#        \"num_layers\": len(model.transformer.layers),\n",
        "#        \"batch_size\": batch_size,\n",
        "#        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "#        \"max_seq_length\": model.max_seq_length,\n",
        "#    }\n",
        "#)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    # Train with two-tier validation during epoch\n",
        "    train_loss, train_acc = train_epoch(\n",
        "        model, \n",
        "        train_loader, \n",
        "        tiny_val_loader,  # Tiny validation for frequent checks\n",
        "        full_val_loader,  # Full validation for accurate metrics\n",
        "        criterion, \n",
        "        optimizer, \n",
        "        device,\n",
        "        tiny_val_every_n_batches=tiny_val_every_n_batches,\n",
        "        full_val_every_n_batches=full_val_every_n_batches\n",
        "    )\n",
        "    \n",
        "    # Full validation at end of epoch (optional - can skip if you want)\n",
        "    print(\"\\nRunning full validation at end of epoch...\")\n",
        "    val_loss, val_acc = evaluate(model, full_val_loader, criterion, device)\n",
        "    \n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "    \n",
        "    # Log to wandb\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_accuracy\": train_acc,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_accuracy\": val_acc,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr']\n",
        "    })\n",
        "    \n",
        "    # Print results\n",
        "    print(f\"\\nEpoch {epoch + 1} Results:\")\n",
        "    print(f\"  Train - Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
        "    print(f\"  Val   - Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
        "    print(f\"  Learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "    \n",
        "    # Track best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        print(f\"  ✓ New best validation accuracy: {best_val_acc:.2f}%\")\n",
        "        # Optionally save model checkpoint\n",
        "        # torch.save(model.state_dict(), 'best_model.pt')\n",
        "    \n",
        "    print()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Training completed!\")\n",
        "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "wandb.finish()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "datascience",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
