{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenizer and Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tokenizer import ARCTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 18\n",
            "Special tokens: {'PAD': 10, 'SOS': 11, 'EOS': 12, 'TRAIN': 13, 'TEST': 14, 'INPUT': 15, 'OUTPUT': 16, 'NEWLINE': 17}\n",
            "\n",
            "Test grid: [[1, 2, 3], [4, 5, 6]]\n",
            "Tokens: [1, 2, 3, 17, 4, 5, 6]\n",
            "Back to grid: [[1, 2, 3], [4, 5, 6]]\n"
          ]
        }
      ],
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = ARCTokenizer()\n",
        "print(f\"Vocabulary size: {tokenizer.vocab_size}\")\n",
        "print(f\"Special tokens: {tokenizer.token_to_id}\")\n",
        "\n",
        "# Test tokenizer\n",
        "test_grid = [[1, 2, 3], [4, 5, 6]]\n",
        "tokens = tokenizer.grid_to_tokens(test_grid)\n",
        "print(f\"\\nTest grid: {test_grid}\")\n",
        "print(f\"Tokens: {tokens}\")\n",
        "print(f\"Back to grid: {tokenizer.tokens_to_grid(tokens, (2, 3))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Token converter (enrich with position info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from token_converter import TokenTo3DConverter\n",
        "# Initialize converter\n",
        "token_converter = TokenTo3DConverter(tokenizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loader with Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from dataset import ARCDataset, ARCTorchDataset \n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datasets...\n",
            "Training challenges: 400\n",
            "Test challenges: 100\n",
            "\n",
            "Training samples (with augmentation): 614\n",
            "Test samples: 152\n",
            "\n",
            "Sample data:\n",
            "Sample ID: 007bbfb7_orig\n",
            "Challenge ID: 007bbfb7\n",
            "Input sequence length: 5400\n",
            "Target sequence length: 1000\n",
            "Input dims: [(3, 3), (3, 3)]\n",
            "Output dims: [(9, 9), (9, 9)]\n",
            "Test input dims: (3, 3)\n",
            "Test output dims: (9, 9)\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "print(\"Loading datasets...\")\n",
        "train_dataset = ARCDataset(\n",
        "    challenges_path='arc-agi_training_challenges.json',\n",
        "    solutions_path='arc-agi_training_solutions.json'\n",
        ")\n",
        "\n",
        "test_dataset = ARCDataset(\n",
        "    challenges_path='arc-agi_test_challenges.json'\n",
        ")\n",
        "\n",
        "print(f\"Training challenges: {len(train_dataset.get_all_challenges())}\")\n",
        "print(f\"Test challenges: {len(test_dataset.get_all_challenges())}\")\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_torch_dataset = ARCTorchDataset(train_dataset, tokenizer, token_converter=token_converter)\n",
        "test_torch_dataset = ARCTorchDataset(test_dataset, tokenizer, token_converter=token_converter)\n",
        "\n",
        "print(f\"\\nTraining samples (with augmentation): {len(train_torch_dataset)}\")\n",
        "print(f\"Test samples: {len(test_torch_dataset)}\")\n",
        "\n",
        "# Test data loading\n",
        "sample = train_torch_dataset[0]\n",
        "print(f\"\\nSample data:\")\n",
        "print(f\"Sample ID: {sample['sample_id']}\")\n",
        "print(f\"Challenge ID: {sample['challenge_id']}\")\n",
        "print(f\"Input sequence length: {len(sample['input'])}\")\n",
        "print(f\"Target sequence length: {len(sample['target'])}\")\n",
        "print(f\"Input dims: {sample['input_dims']}\")\n",
        "print(f\"Output dims: {sample['output_dims']}\")\n",
        "print(f\"Test input dims: {sample['test_input_dims']}\")\n",
        "print(f\"Test output dims: {sample['test_output_dims']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[11, -1, -1],\n",
              "        [13, -1, -1],\n",
              "        [15, -1, -1],\n",
              "        ...,\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# self.PAD_TOKEN = 10\n",
        "# self.SOS_TOKEN = 11  # Start of sequence\n",
        "# self.EOS_TOKEN = 12  # End of sequence\n",
        "# self.TRAIN_TOKEN = 13  # Start of training example\n",
        "# self.TEST_TOKEN = 14  # Start of test example\n",
        "# self.INPUT_TOKEN = 15  # Start of input grid\n",
        "# self.OUTPUT_TOKEN = 16  # Start of output grid\n",
        "# self.NEWLINE_TOKEN = 17  # Grid separator (], [)\n",
        "train_torch_dataset[0]['input']#[0:300]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[11, -1, -1],\n",
              "        [16, -1, -1],\n",
              "        [ 7,  0,  0],\n",
              "        [ 0,  1,  0],\n",
              "        [ 7,  2,  0],\n",
              "        [ 0,  3,  0],\n",
              "        [ 0,  4,  0],\n",
              "        [ 0,  5,  0],\n",
              "        [ 7,  6,  0],\n",
              "        [ 0,  7,  0],\n",
              "        [ 7,  8,  0],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  1],\n",
              "        [ 0,  1,  1],\n",
              "        [ 7,  2,  1],\n",
              "        [ 0,  3,  1],\n",
              "        [ 0,  4,  1],\n",
              "        [ 0,  5,  1],\n",
              "        [ 7,  6,  1],\n",
              "        [ 0,  7,  1],\n",
              "        [ 7,  8,  1],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  2],\n",
              "        [ 7,  1,  2],\n",
              "        [ 0,  2,  2],\n",
              "        [ 0,  3,  2],\n",
              "        [ 0,  4,  2],\n",
              "        [ 0,  5,  2],\n",
              "        [ 7,  6,  2],\n",
              "        [ 7,  7,  2],\n",
              "        [ 0,  8,  2],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  3],\n",
              "        [ 0,  1,  3],\n",
              "        [ 7,  2,  3],\n",
              "        [ 0,  3,  3],\n",
              "        [ 0,  4,  3],\n",
              "        [ 0,  5,  3],\n",
              "        [ 7,  6,  3],\n",
              "        [ 0,  7,  3],\n",
              "        [ 7,  8,  3],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  4],\n",
              "        [ 0,  1,  4],\n",
              "        [ 7,  2,  4],\n",
              "        [ 0,  3,  4],\n",
              "        [ 0,  4,  4],\n",
              "        [ 0,  5,  4],\n",
              "        [ 7,  6,  4],\n",
              "        [ 0,  7,  4],\n",
              "        [ 7,  8,  4],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  5],\n",
              "        [ 7,  1,  5],\n",
              "        [ 0,  2,  5],\n",
              "        [ 0,  3,  5],\n",
              "        [ 0,  4,  5],\n",
              "        [ 0,  5,  5],\n",
              "        [ 7,  6,  5],\n",
              "        [ 7,  7,  5],\n",
              "        [ 0,  8,  5],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  6],\n",
              "        [ 0,  1,  6],\n",
              "        [ 7,  2,  6],\n",
              "        [ 7,  3,  6],\n",
              "        [ 0,  4,  6],\n",
              "        [ 7,  5,  6],\n",
              "        [ 0,  6,  6],\n",
              "        [ 0,  7,  6],\n",
              "        [ 0,  8,  6],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  7],\n",
              "        [ 0,  1,  7],\n",
              "        [ 7,  2,  7],\n",
              "        [ 7,  3,  7],\n",
              "        [ 0,  4,  7],\n",
              "        [ 7,  5,  7],\n",
              "        [ 0,  6,  7],\n",
              "        [ 0,  7,  7],\n",
              "        [ 0,  8,  7],\n",
              "        [17, -1, -1],\n",
              "        [ 7,  0,  8],\n",
              "        [ 7,  1,  8],\n",
              "        [ 0,  2,  8],\n",
              "        [ 7,  3,  8],\n",
              "        [ 7,  4,  8],\n",
              "        [ 0,  5,  8],\n",
              "        [ 0,  6,  8],\n",
              "        [ 0,  7,  8],\n",
              "        [ 0,  8,  8],\n",
              "        [12, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1],\n",
              "        [10, -1, -1]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_torch_dataset[0]['target'][0:300]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(614, 152)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_torch_dataset), len(test_torch_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autoregressive Dataset for LLM Training\n",
        "\n",
        "For autoregressive training, we need to:\n",
        "1. Concatenate input + target into one sequence\n",
        "2. Create labels shifted by 1 position (next token prediction)\n",
        "3. Use causal masking so model can't see future tokens\n",
        "\n",
        "**Important**: This is NOT data leakage! During training, the model learns to predict the next token given previous tokens. During inference, we'll use the same autoregressive generation process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from exploded_dataset import ARCExplodedDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating exploded training dataset...\n",
            "Exploding 614 base samples...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 614/614 [00:04<00:00, 150.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 88372 exploded samples from 614 base samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create exploded datasets from existing ARCTorchDataset\n",
        "print(\"Creating exploded training dataset...\")\n",
        "train_exploded_dataset = ARCExplodedDataset(train_torch_dataset, tokenizer, sequence_length=5400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 7,  1,  2],\n",
            "        [ 0,  2,  2],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1]]) tensor([11, -1, -1])\n",
            "tensor([[ 7,  1,  2],\n",
            "        [ 0,  2,  2],\n",
            "        [11, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1]]) tensor([16, -1, -1])\n",
            "tensor([[ 7,  1,  2],\n",
            "        [ 0,  2,  2],\n",
            "        [11, -1, -1],\n",
            "        [16, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1]]) tensor([7, 0, 0])\n",
            "tensor([[ 7,  1,  2],\n",
            "        [ 0,  2,  2],\n",
            "        [11, -1, -1],\n",
            "        [16, -1, -1],\n",
            "        [ 7,  0,  0],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1]]) tensor([0, 1, 0])\n",
            "tensor([[ 7,  1,  2],\n",
            "        [ 0,  2,  2],\n",
            "        [11, -1, -1],\n",
            "        [16, -1, -1],\n",
            "        [ 7,  0,  0],\n",
            "        [ 0,  1,  0],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1]]) tensor([7, 2, 0])\n",
            "tensor([[ 7,  1,  2],\n",
            "        [ 0,  2,  2],\n",
            "        [11, -1, -1],\n",
            "        [16, -1, -1],\n",
            "        [ 7,  0,  0],\n",
            "        [ 0,  1,  0],\n",
            "        [ 7,  2,  0],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1]]) tensor([0, 3, 0])\n",
            "tensor([[ 7,  1,  2],\n",
            "        [ 0,  2,  2],\n",
            "        [11, -1, -1],\n",
            "        [16, -1, -1],\n",
            "        [ 7,  0,  0],\n",
            "        [ 0,  1,  0],\n",
            "        [ 7,  2,  0],\n",
            "        [ 0,  3,  0],\n",
            "        [10, -1, -1],\n",
            "        [10, -1, -1]]) tensor([0, 4, 0])\n",
            "tensor([[ 7,  1,  2],\n",
            "        [ 0,  2,  2],\n",
            "        [11, -1, -1],\n",
            "        [16, -1, -1],\n",
            "        [ 7,  0,  0],\n",
            "        [ 0,  1,  0],\n",
            "        [ 7,  2,  0],\n",
            "        [ 0,  3,  0],\n",
            "        [ 0,  4,  0],\n",
            "        [10, -1, -1]]) tensor([0, 5, 0])\n",
            "tensor([[ 7,  1,  2],\n",
            "        [ 0,  2,  2],\n",
            "        [11, -1, -1],\n",
            "        [16, -1, -1],\n",
            "        [ 7,  0,  0],\n",
            "        [ 0,  1,  0],\n",
            "        [ 7,  2,  0],\n",
            "        [ 0,  3,  0],\n",
            "        [ 0,  4,  0],\n",
            "        [ 0,  5,  0]]) tensor([7, 6, 0])\n",
            "tensor([[ 7,  1,  2],\n",
            "        [ 0,  2,  2],\n",
            "        [11, -1, -1],\n",
            "        [16, -1, -1],\n",
            "        [ 7,  0,  0],\n",
            "        [ 0,  1,  0],\n",
            "        [ 7,  2,  0],\n",
            "        [ 0,  3,  0],\n",
            "        [ 0,  4,  0],\n",
            "        [ 0,  5,  0]]) tensor([0, 7, 0])\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    print(train_exploded_dataset[i]['input_3d'][218:228], train_exploded_dataset[i]['target_vector'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modeling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NextTokenPredictor(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer model to predict next token from 3D vectors [value, x, y].\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, vocab_size=18, d_model=256, nhead=8, num_layers=4, \n",
        "                 dim_feedforward=1024, max_seq_length=5400, dropout=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_model = d_model\n",
        "        self.max_seq_length = max_seq_length\n",
        "        \n",
        "        # Embedding for token values (0-17)\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        \n",
        "        # Projection for x, y coordinates (add coordinate information)\n",
        "        self.coord_projection = nn.Linear(2, d_model)  # [x, y] -> d_model\n",
        "        \n",
        "        # Positional encoding (learned)\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(max_seq_length, d_model) * 0.02)\n",
        "        \n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        \n",
        "        # Output projection to vocab\n",
        "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input_3d, attention_mask=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_3d: [batch_size, seq_len, 3] - [value, x, y] vectors\n",
        "            attention_mask: [batch_size, seq_len] - 1 for real tokens, 0 for padding\n",
        "        \n",
        "        Returns:\n",
        "            logits: [batch_size, seq_len, vocab_size] - logits for each position\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = input_3d.shape\n",
        "        \n",
        "        # Extract components\n",
        "        token_values = input_3d[:, :, 0].long()  # [batch_size, seq_len] - token values\n",
        "        coordinates = input_3d[:, :, 1:3].float()  # [batch_size, seq_len, 2] - x, y\n",
        "        \n",
        "        # Embed tokens\n",
        "        token_emb = self.token_embedding(token_values)  # [batch_size, seq_len, d_model]\n",
        "        \n",
        "        # Add coordinate information\n",
        "        coord_emb = self.coord_projection(coordinates)  # [batch_size, seq_len, d_model]\n",
        "        \n",
        "        # Combine token and coordinate embeddings\n",
        "        x = token_emb + coord_emb  # [batch_size, seq_len, d_model]\n",
        "        \n",
        "        # Add positional encoding\n",
        "        x = x + self.pos_encoding[:seq_len].unsqueeze(0)  # [batch_size, seq_len, d_model]\n",
        "        \n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        # Convert attention mask to format expected by transformer\n",
        "        # Transformer expects: True/1 = attend, False/0 = mask out\n",
        "        # Our mask: 1 = real token, 0 = padding\n",
        "        # So we need to invert: padding_mask = 1 - attention_mask\n",
        "        if attention_mask is not None:\n",
        "            padding_mask = (attention_mask == 0)  # True for padding, False for real tokens\n",
        "        else:\n",
        "            padding_mask = None\n",
        "        \n",
        "        # Apply transformer\n",
        "        x = self.transformer(x, src_key_padding_mask=padding_mask)  # [batch_size, seq_len, d_model]\n",
        "        \n",
        "        # Get logits for all positions\n",
        "        logits = self.output_proj(x)  # [batch_size, seq_len, vocab_size]\n",
        "        \n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model\n",
        "model = NextTokenPredictor(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    d_model=256,\n",
        "    nhead=8,\n",
        "    num_layers=4,\n",
        "    dim_feedforward=1024,\n",
        "    max_seq_length=5400,\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "print(f\"Model device: {next(model.parameters()).device}\")\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create DataLoader\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function for batching\"\"\"\n",
        "    input_3d = torch.stack([item['input_3d'] for item in batch])\n",
        "    target_values = torch.stack([torch.tensor(item['target_value'], dtype=torch.long) for item in batch])\n",
        "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
        "    \n",
        "    return {\n",
        "        'input_3d': input_3d,\n",
        "        'target_values': target_values,\n",
        "        'attention_mask': attention_mask\n",
        "    }\n",
        "\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(\n",
        "    train_exploded_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=0  # Set to 0 for notebooks\n",
        ")\n",
        "\n",
        "print(f\"Created DataLoader with {len(train_loader)} batches (batch_size={batch_size})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(dataloader, desc=\"Training\")\n",
        "    for batch in pbar:\n",
        "        # Move to device\n",
        "        input_3d = batch['input_3d'].to(device)  # [batch_size, seq_len, 3]\n",
        "        target_values = batch['target_values'].to(device)  # [batch_size]\n",
        "        attention_mask = batch['attention_mask'].to(device)  # [batch_size, seq_len]\n",
        "        \n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_3d=input_3d, attention_mask=attention_mask)  # [batch_size, seq_len, vocab_size]\n",
        "        \n",
        "        # Get logits for the last non-padding position (where we predict)\n",
        "        # Find last non-padding position for each sequence\n",
        "        batch_size = input_3d.size(0)\n",
        "        seq_lengths = attention_mask.sum(dim=1) - 1  # -1 because we want the position before the target\n",
        "        last_logits = logits[torch.arange(batch_size), seq_lengths]  # [batch_size, vocab_size]\n",
        "        \n",
        "        # Compute loss\n",
        "        loss = criterion(last_logits, target_values)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Metrics\n",
        "        total_loss += loss.item()\n",
        "        predictions = last_logits.argmax(dim=1)\n",
        "        correct += (predictions == target_values).sum().item()\n",
        "        total += target_values.size(0)\n",
        "        \n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'acc': f'{100 * correct / total:.2f}%'\n",
        "        })\n",
        "    \n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# Train for a few epochs\n",
        "num_epochs = 3\n",
        "print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "    avg_loss, accuracy = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    scheduler.step()\n",
        "    \n",
        "    print(f\"Epoch {epoch + 1} - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "print(\"\\nTraining completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation function\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    \"\"\"Evaluate model on dataset\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            input_3d = batch['input_3d'].to(device)\n",
        "            target_values = batch['target_values'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            \n",
        "            logits = model(input_3d=input_3d, attention_mask=attention_mask)\n",
        "            \n",
        "            batch_size = input_3d.size(0)\n",
        "            seq_lengths = attention_mask.sum(dim=1) - 1\n",
        "            last_logits = logits[torch.arange(batch_size), seq_lengths]\n",
        "            \n",
        "            loss = criterion(last_logits, target_values)\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "            predictions = last_logits.argmax(dim=1)\n",
        "            correct += (predictions == target_values).sum().item()\n",
        "            total += target_values.size(0)\n",
        "    \n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# Test on a few samples\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Testing model on a few samples...\")\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    sample = train_exploded_dataset[0]\n",
        "    input_3d = sample['input_3d'].unsqueeze(0).to(device)  # [1, seq_len, 3]\n",
        "    attention_mask = sample['attention_mask'].unsqueeze(0).to(device)  # [1, seq_len]\n",
        "    target_value = sample['target_value']\n",
        "    \n",
        "    logits = model(input_3d=input_3d, attention_mask=attention_mask)\n",
        "    seq_len = attention_mask.sum().item() - 1\n",
        "    prediction = logits[0, seq_len].argmax().item()\n",
        "    \n",
        "    token_names = {10: 'PAD', 11: 'SOS', 12: 'EOS', 13: 'TRAIN', 14: 'TEST', \n",
        "                   15: 'INPUT', 16: 'OUTPUT', 17: 'NEWLINE'}\n",
        "    \n",
        "    print(f\"Sample prediction:\")\n",
        "    print(f\"  Target token: {target_value} ({token_names.get(target_value, target_value)})\")\n",
        "    print(f\"  Predicted token: {prediction} ({token_names.get(prediction, prediction)})\")\n",
        "    print(f\"  Correct: {prediction == target_value}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "datascience",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
